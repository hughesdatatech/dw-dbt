version: 2.1

orbs:
  python: circleci/python@2.1.1
  slack: circleci/slack@4.10.1
  gh: circleci/github-cli@2.2.0

parameters: #-pp
  manual-trigger-pp:
    type: string
    default: ""
  dbt-test-vars:
    type: string
    default: "--vars 'test_row_limit: 10'"
  dbt-compile-vars:
    type: string
    default: >
      event_name_override: pipeline_compile
  dbt-metadata-vars:
    type: string
    default: >
      pipeline_key: << pipeline.id >> | << pipeline.number >>,
      pipeline_project_metadata: << pipeline.project.git_url >> | << pipeline.project.type >> | << pipeline.git.tag >> | << pipeline.git.branch >> | << pipeline.git.revision >> | << pipeline.git.base_revision >>,
      pipeline_schedule_metadata: << pipeline.in_setup >> | << pipeline.trigger_source >> | << pipeline.schedule.name >> | << pipeline.schedule.id >>
  gen-state-args:
    type: string
    default: ""

commands:

  slack-notify-co:
    parameters:
      notify-text:
        description: Notification text to be sent to Slack
        default: ""
        type: string
      on-event:
        default: "always"
        type: string
    steps:
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          custom: |
            {
              "blocks": [
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "plain_text",
                      "text": "<<parameters.notify-text>>",
                      "emoji": true
                    }
                  ]
                }
              ]
            }
          event: <<parameters.on-event>>          

  setup-and-install-requirements-co:
    steps:
      - checkout
      - slack-notify-co:
          notify-text: "Replacing secrets..."
      - run:
          name: Setup and install requirements
          command: |
            mkdir -p ~/.dbt
            mv .circleci/profiles.yml ~/.dbt/profiles.yml 
            # For dbt profile
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_ACCOUNT/${CCI_TARGET_SNOWFLAKE_ACCOUNT}/g" ~/.dbt/profiles.yml
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_USER/${CCI_TARGET_SNOWFLAKE_USER}/g" ~/.dbt/profiles.yml
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_PASSWORD/${CCI_TARGET_SNOWFLAKE_PASSWORD}/g" ~/.dbt/profiles.yml
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_ROLE/${CCI_TARGET_SNOWFLAKE_ROLE}/g" ~/.dbt/profiles.yml
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_DBNAME/${CCI_TARGET_SNOWFLAKE_DBNAME}/g" ~/.dbt/profiles.yml
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_WAREHOUSE/${CCI_TARGET_SNOWFLAKE_WAREHOUSE}/g" ~/.dbt/profiles.yml
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_DBT_SCHEMA/${CCI_TARGET_SNOWFLAKE_DBT_SCHEMA}/g" ~/.dbt/profiles.yml
            #cat  ~/.dbt/profiles.yml
            # For Meltano env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_USER/${CCI_TARGET_SNOWFLAKE_USER}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_PASSWORD/${CCI_TARGET_SNOWFLAKE_PASSWORD}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_ACCOUNT/${CCI_TARGET_SNOWFLAKE_ACCOUNT}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_DBNAME/${CCI_TARGET_SNOWFLAKE_DBNAME}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_WAREHOUSE/${CCI_TARGET_SNOWFLAKE_WAREHOUSE}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_DEFAULT_TARGET_SCHEMA/${CCI_TARGET_SNOWFLAKE_DEFAULT_TARGET_SCHEMA}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_DBT_SCHEMA/${CCI_TARGET_SNOWFLAKE_DBT_SCHEMA}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_FILE_FORMAT/${CCI_TARGET_SNOWFLAKE_FILE_FORMAT}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_S3_BUCKET/${CCI_TARGET_SNOWFLAKE_S3_BUCKET}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_STAGE/${CCI_TARGET_SNOWFLAKE_STAGE}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_AWS_ACCESS_KEY_ID/${CCI_TARGET_SNOWFLAKE_AWS_ACCESS_KEY_ID}/g" .circleci/.env
            sed -i -e "s/CCI_TARGET_SNOWFLAKE_AWS_SECRET_ACCESS_KEY/${CCI_TARGET_SNOWFLAKE_AWS_SECRET_ACCESS_KEY}/g" .circleci/.env
            mv .circleci/.env dw-meltano/dw-ownbackup/.env
            #cat dw-meltano/dw-ownbackup/.env
            mv .circleci/requirements.txt  ~/.dbt/requirements.txt
      - slack-notify-co:
          notify-text: "Installing Python reqs..."
      - python/install-packages:
            pkg-manager: pip
            app-dir: ~/.dbt/  # if your requirements.txt isn't in the root directory.
            # pip-dependency-file: test-requirements.txt  # if you have a different name for your requirements file, maybe one that combines your runtime and test requirements.
      - slack-notify-co:
          notify-text: "Installing dbt deps and Meltano..."
      - run:
          name: Run dbt deps
          command: cd dw && dbt deps
      - run:
          name: Install meltano
          command: pipx install "meltano"
      - run:
          name: Install rest api extractor
          command: cd dw-meltano/dw-ownbackup && meltano install extractor tap-rest-api-msdk
      - run:
          name: Install snowflake loader
          command: cd dw-meltano/dw-ownbackup && meltano add loader target-snowflake

  compile-dbt-co:
    parameters:
      compile-params:
        description: Optional arguments to be passed to the dbt compile command
        default: ""
        type: string
    steps:
      - slack-notify-co:
          notify-text: "Compiling project and checkpointing..."
      - run:
          name: Run dbt compile
          command: cd dw && dbt compile <<parameters.compile-params>>
      - run:
          name: Run pre-commit
          command: cd dw && pre-commit run --all-files

  docs-dbt-co:
    steps:
      - run:
          name: Run dbt docs
          command: cd dw && dbt docs generate --target-path ../docs
      - run:
          name: Push docs
          command: |
            cd dw
            # email and name are required to confirm identity
            git config --global user.email "hughesdatatech@gmail.com"
            git config --global user.name "$CIRCLE_USERNAME"
            git add ../docs/
            git commit -m "[skip ci] dbt docs gen"
            git push --repo="$CIRCLE_REPOSITORY_URL" --set-upstream origin development
      
  setup-and-compile-co:
    parameters:
      compile-params:
        description: Optional arguments to be passed to the dbt compile command
        default: ""
        type: string
    steps:
      - checkout
      # command is to be replace

  extract-and-load-co:
    parameters:
      run-params:
        description: Optional arguments to be passed to the meltano run command
        default: ""
        type: string
    steps:
      - slack-notify-co:
          notify-text: "Meltano extract/load starting..."
      - run:
          name: Generate state for .env file
          command: cd dw-meltano/dw-ownbackup && python gen_statex.py << pipeline.parameters.gen-state-args >>
      - run:
          name: Extract/load json data
          command: cd dw-meltano/dw-ownbackup && meltano run tap-rest-api-msdk target-snowflake
      - slack-notify-co:
          notify-text: "Meltano extract/load succeeded!"
          on-event: "pass"
      - slack-notify-co:
          notify-text: "Meltano extract/load failed!"
          on-event: "fail"

  log-pipeline-action-co:
    parameters:
      run-params:
        description: Optional arguments to be passed to the dbt run-operation command
        default: ""
        type: string
    steps:
      - run:
          name: Run dbt run-operation
          command: cd dw && dbt run-operation process_log_handler <<parameters.run-params>>
      
  dbt-build-co:
    parameters:
      build-params:
        description: Optional arguments to be passed to the dbt build command
        default: "--exclude tag:demo tag:pit"
        type: string
    steps:
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          custom: |
            {
              "blocks": [
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "plain_text",
                      "text": "starting dbt transform...",
                      "emoji": true
                    }
                  ]
                }
              ]
            }
          event: always
      - run:
          name: Run dbt build
          command: cd dw && dbt build <<parameters.build-params>>
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          custom: |
            {
              "blocks": [
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "plain_text",
                      "text": "dbt transform succeeded!",
                      "emoji": true
                    }
                  ]
                }
              ]
            }
          event: pass
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          custom: |
            {
              "blocks": [
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "plain_text",
                      "text": "dbt transform failed!",
                      "emoji": true
                    }
                  ]
                }
              ]
            }
          event: fail

jobs: #-jb

  setup-and-compile-dbt-jb:
    docker:
      - image: cimg/python:3.9.7
    steps:
      - setup-and-install-requirements-co
      - compile-dbt-co
      - extract-and-load-co
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: pass
          template: basic_success_1
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: fail
          template: basic_fail_1

  dbt-sf-runner-daily-jb:
    docker:
      - image: cimg/python:3.9.7
    steps:
      - setup-and-compile-co:
          compile-params: >
            --vars '{
            << pipeline.parameters.dbt-metadata-vars >>,
            << pipeline.parameters.dbt-compile-vars >>
            }'
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: pipeline, event_name: log_pipeline_action, sequence_description: on_run_start}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: << pipeline.id >> | << pipeline.number >>
            }'
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: meltano_project, event_name: log_pipeline_action, sequence_description: on_run_start}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: dw-meltano
            }'
      - extract-and-load-co:
          run-params: ""
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: meltano_project, event_name: log_pipeline_action, sequence_description: on_run_end}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: dw-meltano
            }'
      - dbt-build-co:
          build-params: >
            --exclude tag:demo tag:pit 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>
            }'
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: pipeline, event_name: log_pipeline_action, sequence_description: on_run_end}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: << pipeline.id >> | << pipeline.number >>
            }'
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: pass
          template: basic_success_1
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: fail
          template: basic_fail_1

  dbt-sf-runner-el-only-jb:
    docker:
      - image: cimg/python:3.9.7
    steps:
      - setup-and-compile-co:
          compile-params: >
            --vars '{
            << pipeline.parameters.dbt-metadata-vars >>,
            << pipeline.parameters.dbt-compile-vars >>
            }'
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: pipeline, event_name: log_pipeline_action, sequence_description: on_run_start}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: << pipeline.id >> | << pipeline.number >>
            }'
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: meltano_project, event_name: log_pipeline_action, sequence_description: on_run_start}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: dw-meltano
            }'
      - extract-and-load-co:
          run-params: ""
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: meltano_project, event_name: log_pipeline_action, sequence_description: on_run_end}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: dw-meltano
            }'
      - log-pipeline-action-co:
          run-params: >
            --args '{object_type: pipeline, event_name: log_pipeline_action, sequence_description: on_run_end}' 
            --vars '{ 
            << pipeline.parameters.dbt-metadata-vars >>,
            object_identifier_override: << pipeline.id >> | << pipeline.number >>
            }'
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: pass
          template: basic_success_1
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: fail
          template: basic_fail_1
  
  dbt-sf-runner-monthly-pit-jb:
    docker:
      - image: cimg/python:3.9.7
    steps:
      - setup-and-compile-co:
          compile-params: ""
      - dbt-build-co:
          build-params: "--exclude tag:demo"
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: pass
          template: basic_success_1
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: fail
          template: basic_fail_1

  dbt-sf-runner-test-jb:
    docker:
      - image: cimg/python:3.9.7
    steps:
      - setup-and-compile-co:
          compile-params: "--target arc_test"
      - dbt-build-co:
          build-params: "--target arc_test << pipeline.parameters.dbt-test-vars >> --exclude tag:demo"
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: pass
          template: basic_success_1
      - slack/notify:
          channel: $SLACK_DEFAULT_CHANNEL
          event: fail
          template: basic_fail_1

  #create-a-pr:
    #docker:
      #- image: cimg/python:3.9.7
    #steps:
      #- checkout
      #- run:
          #name: git test
          #command: cd dw && git --help
      #- gh/setup
      #- run:
          #command: |
            #gh pr create --title "Bugfix from $CIRCLE_BRANCH"
          #name: Create Pull Request
      #- gh/clone
             
workflows: #-wf
  version: 2

  # Setup and compile workflow, triggered upon push to main or development (or manual trigger)
  setup-and-compile-wf:
    when:
      or:
        - equal: [ "setup-and-compile", << pipeline.parameters.manual-trigger-pp >> ]
        - equal: [ "webhook", << pipeline.trigger_source >> ]
    jobs:
      - setup-and-compile-dbt-jb:
          filters:
            branches:
              only: 
                #- main
                - development

  # Daily scheduled workflow for the entire pipeline, excluding monthly PIT tables (or manual trigger)
  scheduled-pipeline-daily-wf: 
    when:
      or:
        - equal: [ "dbt-sf-runner-daily", << pipeline.parameters.manual-trigger-pp >> ]
        - equal: [ "dbt-sf-runner-daily", << pipeline.schedule.name >> ]
    jobs:
      - dbt-sf-runner-daily-jb

  # EL only via manual trigger
  manual-pipeline-el-only-wf: 
    when:
      or:
        - equal: [ "dbt-sf-runner-el-only-jb", << pipeline.parameters.manual-trigger-pp >> ]
    jobs:
      - dbt-sf-runner-el-only-jb

  # Monthly scheduled workflow for the entire pipeline, including PIT tables (or manual trigger)
  scheduled-pipeline-monthly-pit-wf:
    when:
      or:
        - equal: [ "dbt-sf-runner-monthly-pit", << pipeline.parameters.manual-trigger-pp >> ]
        - equal: [ "dbt-sf-runner-monthly-pit", << pipeline.schedule.name >> ]
    jobs:
      - dbt-sf-runner-monthly-pit-jb

  # Test scheduled workflow (or manual trigger)
  test-wf:
    when:
      or:
        - equal: [ "dbt-sf-runner-test", << pipeline.parameters.manual-trigger-pp >> ]
        - equal: [ "dbt-sf-runner-test", << pipeline.schedule.name >> ]
    jobs:
      - dbt-sf-runner-test-jb
  